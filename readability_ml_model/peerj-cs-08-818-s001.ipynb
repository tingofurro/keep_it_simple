{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "# %%\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "# %%\n",
    "df = pd.read_csv(\"../input/ptdata/mixdata.csv\")\n",
    "# %%\n",
    "df.describe()\n",
    "# %%\n",
    "# df.drop(df.columns[[7]], axis=1, inplace=True)\n",
    "# df.drop(df.columns[[8]], axis=1, inplace=True)\n",
    "# %%\n",
    "dataset2 = df.drop(columns=[\"complexity\"])\n",
    "dataset2.corrwith(df.complexity).plot.bar(\n",
    "    figsize=(20, 10),\n",
    "    title=\"Correlation with complexitylevel\",\n",
    "    fontsize=20,\n",
    "    rot=45,\n",
    "    grid=True,\n",
    ")\n",
    "# %%\n",
    "df.describe()\n",
    "# %%\n",
    "df.drop(df.columns[[9]], axis=1, inplace=True)\n",
    "# %%\n",
    "df.head()\n",
    "# %%\n",
    "df[2:18822]\n",
    "# %%\n",
    "import seaborn as sns\n",
    "\n",
    "# %%\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "no_id_data = df.copy()\n",
    "no_id_data.drop(\"id\", axis=1, inplace=True)\n",
    "sns.heatmap(data=no_id_data.corr(), annot=True)\n",
    "plt.show()\n",
    "# %%\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# %%\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# %%\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "log_pred = classifier.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, log_pred))\n",
    "print(confusion_matrix(y_test, log_pred))\n",
    "# Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy is\", accuracy_score(log_pred, y_test))\n",
    "# %%\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../input/ptdata/mixdata.csv\")\n",
    "\n",
    "X = df.iloc[:, :1].values\n",
    "y = df.iloc[:, 2].values\n",
    "\n",
    "y = label_binarize(y, classes=[0, 1, 2, 3, 4, 5, 6])\n",
    "n_classes = 7\n",
    "my_classes = [\n",
    "    \"Plain_English\",\n",
    "    \"Very_Easy\",\n",
    "    \"Fairly_difficuly\",\n",
    "    \"Fairly_Easy\",\n",
    "    \"Difficult\",\n",
    "    \" Easy\",\n",
    "    \"very_Difficult\",\n",
    "]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# classifier\n",
    "# clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "# y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "\n",
    "# clf = OneVsRestClassifier(KNeighborsClassifier(random_state=0))\n",
    "# y_score= clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression(random_state=0))\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# clf = OneVsRestClassifier(GaussianNB(random_state=0))\n",
    "# y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label=\"ROC curve (area = %0.2f)\" % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"(Receiver operating characteristic)\" + my_classes[i])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "# %%\n",
    "# roctry\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Data Type\": df.dtypes,\n",
    "        \"Null Value\": pd.isnull(df).any(),\n",
    "        \"Count\": list(map(lambda column: len(df[column].unique()), df.columns)),\n",
    "    }\n",
    ")\n",
    "# %%\n",
    "# roctry\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "unique_cat = set(df[\"Class_Label\"].unique())\n",
    "df[\"Class_Label_\"] = pd.Categorical(df[\"Class_Label\"], categories=unique_cat).codes\n",
    "\n",
    "y = df[\"Class_Label_\"]\n",
    "X = df.drop([\"Class_Label\", \"Class_Label_\", \"id\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# %%\n",
    "# roctry\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pca_pipe = Pipeline(steps=[(\"norm\", StandardScaler()), (\"pca\", PCA(n_components=2))]).fit(X_train)\n",
    "pc = pca_pipe.transform(X_train)\n",
    "pc_1, pc_2 = list(zip(*pc))\n",
    "\n",
    "groups = pd.DataFrame({\"pc_1\": pc_1, \"pc_2\": pc_2, \"y\": y_train}).groupby(\"y\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for group, color, name in zip(\n",
    "    df[\"Class_Label_\"].unique(),\n",
    "    [\"#0080ff\", \"#ff6600\", \"#9966ff\", \"#DFFF00\", \"#40E0D0\", \"#000000\", \"#00FF00\"],\n",
    "    df[\"Class_Label\"].unique(),\n",
    "):\n",
    "    pc_group = groups.get_group(group)\n",
    "    plt.scatter(pc_group.loc[:, \"pc_1\"], pc_group.loc[:, \"pc_2\"], color=color, label=name)\n",
    "plt.legend()\n",
    "# %%\n",
    "# roc try\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "# clf = LogisticRegression()\n",
    "classifier_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"norm\", MinMaxScaler()),\n",
    "        (\"classifier\", classifier),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_name = \"C\"\n",
    "param_range = np.logspace(-4, 1, 50)\n",
    "\n",
    "train_score, test_score = validation_curve(\n",
    "    classifier_pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring=\"accuracy\",\n",
    "    param_name=\"classifier__{}\".format(param_name),\n",
    "    param_range=param_range,\n",
    ")\n",
    "\n",
    "train_max = list(map(np.max, train_score))\n",
    "train_min = list(map(np.min, train_score))\n",
    "train_mean = list(map(np.mean, train_score))\n",
    "\n",
    "test_max = list(map(np.max, test_score))\n",
    "test_min = list(map(np.min, test_score))\n",
    "test_mean = list(map(np.mean, test_score))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for min_val, max_val, mean_val, color, name in zip(\n",
    "    [train_min, test_min],\n",
    "    [train_max, test_max],\n",
    "    [train_mean, test_mean],\n",
    "    [\"blue\", \"orange\"],\n",
    "    [\"Train Score\", \"Test Score\"],\n",
    "):\n",
    "    plt.plot(param_range, mean_val, color=color, label=name)\n",
    "    plt.fill_between(param_range, max_val, min_val, color=color, alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Hyper Parameter ({})\".format(param_name))\n",
    "plt.ylabel(\"Score (Accuracy)\")\n",
    "sns.despine()\n",
    "\n",
    "\n",
    "def multi_class_roc(class_code):\n",
    "    classifier_pipe.fit(X_train, y_train)\n",
    "    return roc_auc_score(\n",
    "        np.where(y_test == class_code, 1, 0),\n",
    "        [val[class_code] for val in classifier_pipe.predict_proba(X_test)],\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"roc auc score for Plain_English= {}\".format(multi_class_roc(0)))\n",
    "print(\"roc auc score for Fairly_Easy = {}\".format(multi_class_roc(1)))\n",
    "print(\"roc auc score Very_Easy = {}\".format(multi_class_roc(2)))\n",
    "print(\"roc auc score Fairly_difficult = {}\".format(multi_class_roc(3)))\n",
    "print(\"roc auc score Very_difficult = {}\".format(multi_class_roc(4)))\n",
    "print(\"roc auc score Difficult = {}\".format(multi_class_roc(5)))\n",
    "print(\"roc auc score Easy = {}\".format(multi_class_roc(6)))\n",
    "print(\n",
    "    \"average roc auc score = {}\".format(\n",
    "        np.mean(\n",
    "            [\n",
    "                multi_class_roc(0),\n",
    "                multi_class_roc(1),\n",
    "                multi_class_roc(2),\n",
    "                multi_class_roc(3),\n",
    "                multi_class_roc(4),\n",
    "                multi_class_roc(5),\n",
    "                multi_class_roc(6),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# %%\n",
    "# try\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "log_pred = classifier.predict(X_test)\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, log_pred))\n",
    "# print(confusion_matrix(y_test, log_pred))\n",
    "# Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy is\", accuracy_score(log_pred, y_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, log_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp = disp.plot(cmap=plt.cm.Blues, values_format=\"g\")\n",
    "plt.show()\n",
    "# %%\n",
    "# K-Nearest Neighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=8)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "knn_pred = classifier.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, knn_pred))\n",
    "print(confusion_matrix(y_test, knn_pred))\n",
    "# Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy is\", accuracy_score(knn_pred, y_test))\n",
    "# %%\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../input/ptdata/mixdata.csv\")\n",
    "\n",
    "X = df.iloc[:, :1].values\n",
    "y = df.iloc[:, 2].values\n",
    "\n",
    "y = label_binarize(y, classes=[0, 1, 2, 3, 4, 5, 6])\n",
    "n_classes = 7\n",
    "my_classes = [\n",
    "    \"Plain_English\",\n",
    "    \"Very_Easy\",\n",
    "    \"Fairly_difficuly\",\n",
    "    \"Fairly_Easy\",\n",
    "    \"Difficult\",\n",
    "    \" Easy\",\n",
    "    \"very_Difficult\",\n",
    "]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# classifier\n",
    "# clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "\n",
    "knn_9 = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=9))\n",
    "# fit the model to the training set\n",
    "knn_9.fit(X_train, y_train)\n",
    "\n",
    "# predict on the test-set\n",
    "y_pred_9 = knn_9.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Model accuracy score with k=9 : {0:0.4f}\".format(accuracy_score(y_test, y_pred_9)))\n",
    "\n",
    "y_pred_train = knn_9.predict(X_train)\n",
    "\n",
    "print(\"Training-set accuracy score: {0:0.4f}\".format(accuracy_score(y_train, y_pred_train)))\n",
    "\n",
    "# y_pred_1 = knn_9.predict_proba(X_test)\n",
    "y_scores = knn_9.predict_proba(X_test)\n",
    "\n",
    "# print(y_scores)\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label=\"ROC curve (area = %0.2f)\" % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"(Receiver operating characteristic)\" + my_classes[i])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "# %%\n",
    "# Support Vector Machine's\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "svc_pred = classifier.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, svc_pred))\n",
    "print(confusion_matrix(y_test, svc_pred))\n",
    "# Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy is\", accuracy_score(svc_pred, y_test))\n",
    "# %%\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../input/ptdata/mixdata.csv\")\n",
    "\n",
    "X = df.iloc[:, :1].values\n",
    "y = df.iloc[:, 2].values\n",
    "\n",
    "y = label_binarize(y, classes=[0, 1, 2, 3, 4, 5, 6])\n",
    "n_classes = 7\n",
    "my_classes = [\n",
    "    \"Plain_English\",\n",
    "    \"Very_Easy\",\n",
    "    \"Fairly_difficuly\",\n",
    "    \"Fairly_Easy\",\n",
    "    \"Difficult\",\n",
    "    \" Easy\",\n",
    "    \"very_Difficult\",\n",
    "]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# classifier\n",
    "clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label=\"ROC curve (area = %0.2f)\" % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"(Receiver operating characteristic)\" + my_classes[i])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "# %%\n",
    "# Decision Tree's\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy is\", accuracy_score(y_pred, y_test))\n",
    "# %%\n",
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "nv_pred = classifier.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, nv_pred))\n",
    "print(confusion_matrix(y_test, nv_pred))\n",
    "# Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy is\", accuracy_score(nv_pred, y_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, nv_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp = disp.plot(cmap=plt.cm.Blues, values_format=\"g\")\n",
    "plt.show()\n",
    "# %%\n",
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n",
    "from sklearn.metrics import accuracy_score as asc\n",
    "\n",
    "print(asc(y_test, pred))\n",
    "# %%\n",
    "# tryyy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "matrix_1 = confusion_matrix(y_test, log_pred)\n",
    "matrix_2 = confusion_matrix(y_test, svc_pred)\n",
    "matrix_3 = confusion_matrix(y_test, knn_pred)\n",
    "matrix_4 = confusion_matrix(y_test, nv_pred)\n",
    "# %%\n",
    "# try\n",
    "df_1 = pd.DataFrame(\n",
    "    matrix_1,\n",
    "    index=[\n",
    "        \"Plain_English\",\n",
    "        \"Very_Easy\",\n",
    "        \"Fairly_difficult\",\n",
    "        \"Fairly_Easy\",\n",
    "        \"Dificult\",\n",
    "        \"Easy\",\n",
    "        \"very_difficult\",\n",
    "    ],\n",
    "    columns=[\n",
    "        \"Plain_English\",\n",
    "        \"Very_Easy\",\n",
    "        \"Fairly_difficult\",\n",
    "        \"Fairly_Easy\",\n",
    "        \"Dificult\",\n",
    "        \"Easy\",\n",
    "        \"very_difficult\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_2 = pd.DataFrame(\n",
    "    matrix_2,\n",
    "    index=[\n",
    "        \"Plain_English\",\n",
    "        \"Very_Easy\",\n",
    "        \"Fairly_difficult\",\n",
    "        \"Fairly_Easy\",\n",
    "        \"Dificult\",\n",
    "        \"Easy\",\n",
    "        \"very_difficult\",\n",
    "    ],\n",
    "    columns=[\n",
    "        \"Plain_English\",\n",
    "        \"Very_Easy\",\n",
    "        \"Fairly_difficult\",\n",
    "        \"Fairly_Easy\",\n",
    "        \"Dificult\",\n",
    "        \"Easy\",\n",
    "        \"very_difficult\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_3 = pd.DataFrame(\n",
    "    matrix_3,\n",
    "    index=[\n",
    "        \"Plain_English\",\n",
    "        \"Very_Easy\",\n",
    "        \"Fairly_difficult\",\n",
    "        \"Fairly_Easy\",\n",
    "        \"Dificult\",\n",
    "        \"Easy\",\n",
    "        \"very_difficult\",\n",
    "    ],\n",
    "    columns=[\n",
    "        \"Plain_English\",\n",
    "        \"Very_Easy\",\n",
    "        \"Fairly_difficult\",\n",
    "        \"Fairly_Easy\",\n",
    "        \"Dificult\",\n",
    "        \"Easy\",\n",
    "        \"very_difficult\",\n",
    "    ],\n",
    ")\n",
    "df_4 = pd.DataFrame(\n",
    "    matrix_4,\n",
    "    index=[\n",
    "        \"Plain_English\",\n",
    "        \"Very_Easy\",\n",
    "        \"Fairly_difficult\",\n",
    "        \"Fairly_Easy\",\n",
    "        \"Dificult\",\n",
    "        \"Easy\",\n",
    "        \"very_difficult\",\n",
    "    ],\n",
    "    columns=[\n",
    "        \"Plain_English\",\n",
    "        \"Very_Easy\",\n",
    "        \"Fairly_difficult\",\n",
    "        \"Fairly_Easy\",\n",
    "        \"Dificult\",\n",
    "        \"Easy\",\n",
    "        \"very_difficult\",\n",
    "    ],\n",
    ")\n",
    "# %%\n",
    "# try\n",
    "plt.figure(figsize=(100, 10))\n",
    "plt.subplots_adjust(hspace=0.50)\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.title('confusion_matrix(logistic regression)')\n",
    "# sns.heatmap(df_1, annot=True,cmap='Blues',values_format='g')\n",
    "\n",
    "target_names = [\n",
    "    \"Plain_English\",\n",
    "    \"Very_Easy\",\n",
    "    \"Fairly_difficult\",\n",
    "    \"Fairly_Easy\",\n",
    "    \"Dificult\",\n",
    "    \"Easy\",\n",
    "    \"very_difficult\",\n",
    "]\n",
    "labels_names = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "cm = confusion_matrix(y_test, log_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues, values_format=\"g\")\n",
    "plt.title(\"confusion_matrix(logistic regression)\")\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_test, svc_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues, values_format=\"g\")\n",
    "plt.title(\"confusion_matrix(Support vector machine)\")\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_test, knn_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues, values_format=\"g\")\n",
    "plt.title(\"confusion_matrix(KNearest Neighbour)\")\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_test, nv_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues, values_format=\"g\")\n",
    "plt.title(\"confusion_matrix(Naive Bayes)\")\n",
    "plt.show()\n",
    "\n",
    "# plt.subplot(1,3,2)\n",
    "# plt.title('confusion_matrix(Support vector machines)')\n",
    "# sns.heatmap(df_2, annot=True,cmap='Greens')\n",
    "# plt.subplot(1,3,3)\n",
    "# plt.title('confusion_matrix(Random forest)')\n",
    "# sns.heatmap(df_3, annot=True,cmap='Reds')\n",
    "# plt.show()\n",
    "# %%\n",
    "X = df.iloc[:, 1:-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "# %%\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "y = label_encoder_y.fit_transform(y)\n",
    "y = to_categorical(y)\n",
    "# %%\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)\n",
    "# %%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# %%\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_dim=8, activation=\"relu\"))\n",
    "# model.add(Dense(64, activation = 'relu'))\n",
    "# model.add(Dense(128, activation = 'relu'))\n",
    "# model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "# model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(7, activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "# %%\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=0)\n",
    "# %%\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(\"Accuracy :{}\", format(accuracy))\n",
    "# %%\n",
    "# tryroc\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_scores = model.predict_proba(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes = 7\n",
    "my_classes = [\n",
    "    \"Plain_English\",\n",
    "    \"Very_Easy\",\n",
    "    \"Fairly_difficuly\",\n",
    "    \"Fairly_Easy\",\n",
    "    \"Difficult\",\n",
    "    \" Easy\",\n",
    "    \"very_Difficult\",\n",
    "]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label=\"ROC curve (area = %0.2f)\" % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"(Receiver operating characteristic)\" + my_classes[i])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "# %%\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_scores.argmax(axis=1))\n",
    "matrix\n",
    "cm = metrics.confusion_matrix(y_test.argmax(axis=1), y_scores.argmax(axis=1))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp = disp.plot(cmap=plt.cm.Blues, values_format=\"g\")\n",
    "plt.show()\n",
    "# %%\n",
    "print(classification_report(y_test.argmax(axis=1), y_scores.argmax(axis=1)))\n",
    "# %%\n",
    "# calculate the f1-measure\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_score = model.predict_proba(X_test)\n",
    "# %%\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model and predict the accuracy\n",
    "# ann_model = load_model('ANN_Traffic_Model.h5')\n",
    "model.summary()\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy of the Model %.2f%%\" % (results[1] * 100))\n",
    "# print(\"F1 of the Model %.2f%%\" % (results[2]*100))\n",
    "# print(\"Precision of the Model %.2f%%\" % (results[3]*100))\n",
    "# print(\"Recall of the Model %.2f%%\" % (results[4]*100))\n",
    "# y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))\n",
    "# %%\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# precision recall curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in range(7):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_score[:, i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label=\"class {}\".format(i))\n",
    "\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"precision vs. recall curve\")\n",
    "plt.show()\n",
    "# %%\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "# print(y_score[:, 0])\n",
    "\n",
    "\n",
    "# For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(7):\n",
    "    print(i)\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test.ravel(), y_score.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_test, y_score, average=\"micro\")\n",
    "print(\"Average precision score, micro-averaged over all classes: {0:0.2f}\".format(average_precision[\"micro\"]))\n",
    "# %%\n",
    "from itertools import cycle\n",
    "\n",
    "# setup plot details\n",
    "colors = cycle([\"navy\", \"turquoise\", \"darkorange\", \"cornflowerblue\", \"teal\"])\n",
    "\n",
    "plt.figure(figsize=(7, 8))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    (l,) = plt.plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n",
    "    plt.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "lines.append(l)\n",
    "labels.append(\"iso-f1 curves\")\n",
    "(l,) = plt.plot(recall[\"micro\"], precision[\"micro\"], color=\"gold\", lw=2)\n",
    "lines.append(l)\n",
    "labels.append(\"micro-average Precision-recall (area = {0:0.2f})\" \"\".format(average_precision[\"micro\"]))\n",
    "\n",
    "for i, color in zip(range(7), colors):\n",
    "    (l,) = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append(\"Precision-recall for class {0} (area = {1:0.2f})\" \"\".format(i, average_precision[i]))\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Extension of Precision-Recall curve to multi-class\")\n",
    "plt.legend(lines, labels, loc=(0, -0.38), prop=dict(size=14))\n",
    "\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   }
  }
 ]
}
